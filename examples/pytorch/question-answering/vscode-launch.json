{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "[transformers] Eval squad",
            // this model has been pretrained and released by official HF
            // https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad
            // f1 = 93.1584
            // exact_match = 86.91
            // eval_samples = 10784
            "type": "python",
            "request": "launch",
            "env": {
                "CUDA_VISIBLE_DEVICES": "5",
                "TORCH_DISTRIBUTED_DEBUG": "DETAIL",
                "WANDB_MODE": "disabled",
            },
            "justMyCode": false,
            "cwd": "${workspaceFolder}/transformers/examples/pytorch/question-answering",
            "program": "run_qa.py",
            "args": [
                "--model_name_or_path",
                // "vuiseng9/bert-base-uncased-squad",
                // "csarron/bert-base-uncased-squad-v1",
                "bert-large-uncased-whole-word-masking-finetuned-squad",
                // "Intel/bert-large-uncased-sparse-90-unstructured-pruneofa",
                "--sparsemax",
                "--dataset_name", "squad",
                "--do_eval",
                "--per_device_eval_batch_size", "128",
                // "--max_eval_samples", "1000",
                "--max_seq_length", "384",
                "--pad_to_max_length", "False",
                "--doc_stride", "128",
                "--output_dir", "/tmp/vscode-runs/eval-squad1",
                "--overwrite_output_dir"
            ]
        },
        {
            "name": "[transformers] analyze sparsity squad",
            // this model has been pretrained and released by official HF
            // https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad
            // f1 = 93.1584
            // exact_match = 86.91
            // eval_samples = 10784
            "type": "python",
            "request": "launch",
            "env": {
                "CUDA_VISIBLE_DEVICES": "5",
                "TORCH_DISTRIBUTED_DEBUG": "DETAIL",
                "WANDB_MODE": "disabled",
            },
            "justMyCode": false,
            "cwd": "${workspaceFolder}/transformers/examples/pytorch/question-answering",
            "program": "run_qa.py",
            "args": [
                "--model_name_or_path",
                // "vuiseng9/bert-base-uncased-squad",
                // "csarron/bert-base-uncased-squad-v1",
                "bert-large-uncased-whole-word-masking-finetuned-squad",
                // "Intel/bert-large-uncased-sparse-90-unstructured-pruneofa",
                "--dataset_name", "squad",
                "--analyze_sparsity",
                "--do_eval",
                "--per_device_eval_batch_size", "1",
                // "--max_eval_samples", "100",
                "--max_seq_length", "384",
                "--pad_to_max_length", "False",
                "--sparsemax",
                "--doc_stride", "128",
                "--output_dir", "/data5/vchua/dev/apr23-optimum/transformers/examples/pytorch/question-answering/sparsity-report/bert-l-squad-evalset-nopad-sparsemax",
                "--overwrite_output_dir"
            ]
        },
    ]
}